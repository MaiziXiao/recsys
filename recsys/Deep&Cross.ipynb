{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras.layers import Embedding, Input, Dot, Dense, Flatten, Multiply, Concatenate, DenseFeatures\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adagrad, Adam, SGD, RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data_path):\n",
    "    header_data = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "    data = pd.read_csv(data_path, sep='\\t', names=header_data)\n",
    "    data = data.drop(\"timestamp\", axis=1).astype(int)\n",
    "    \n",
    "    num_items = data[\"item_id\"].max()\n",
    "    num_users = data[\"user_id\"].max()\n",
    "    \n",
    "    y = data[\"rating\"]\n",
    "    y = np.where(y==5, 1, 0)\n",
    "\n",
    "    X = data.drop(\"rating\", axis=1)\n",
    "#     X = X.astype('category')\n",
    "    \n",
    "    return X, y, num_items, num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "# User data\n",
    "header_user = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "data_user = pd.read_csv('data/u.user', sep='|', names=header_user)\n",
    "data_user = data_user.drop(['zip_code'], axis=1)\n",
    "\n",
    "# Item data\n",
    "header_item = ['item_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children',\n",
    "        'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', \n",
    "        'Thriller', 'War', 'Western']\n",
    "data_item = pd.read_csv('data/u.item', sep='|', names=header_item, encoding = \"ISO-8859-1\")\n",
    "data_item = data_item.drop(['release_date', 'title', 'video_release_date', 'IMDb_URL'], axis=1)\n",
    "\n",
    "# User Item interaction data\n",
    "X_train, y_train, num_items, num_users = preprocess_data(\"data/ub.base\")\n",
    "X_test , y_test, _, _ = preprocess_data(\"data/ub.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data merge and label separation\n",
    "X_train = X_train.merge(data_user, how=\"left\", left_on=\"user_id\", right_on=\"user_id\", suffixes=(False, False))\n",
    "X_train = X_train.merge(data_item, left_on=\"item_id\", right_on=\"item_id\")\n",
    "X_test = X_test.merge(data_user, left_on=\"user_id\", right_on=\"user_id\")\n",
    "X_test = X_test.merge(data_item, left_on=\"item_id\", right_on=\"item_id\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>unknown</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>executive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>lawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  age gender  occupation  unknown  Action  Adventure  \\\n",
       "0        1        1   24      M  technician        0       0          0   \n",
       "1        2        1   53      F       other        0       0          0   \n",
       "2        5        1   33      F       other        0       0          0   \n",
       "3        6        1   42      M   executive        0       0          0   \n",
       "4       10        1   53      M      lawyer        0       0          0   \n",
       "\n",
       "   Animation  Children  ...  Fantasy  Film-Noir  Horror  Musical  Mystery  \\\n",
       "0          1         1  ...        0          0       0        0        0   \n",
       "1          1         1  ...        0          0       0        0        0   \n",
       "2          1         1  ...        0          0       0        0        0   \n",
       "3          1         1  ...        0          0       0        0        0   \n",
       "4          1         1  ...        0          0       0        0        0   \n",
       "\n",
       "   Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0       0         0    0        0  \n",
       "1        0       0         0    0        0  \n",
       "2        0       0         0    0        0  \n",
       "3        0       0         0    0        0  \n",
       "4        0       0         0    0        0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(x, y, shuffle=True, batch_size=32):\n",
    "  x = x.copy()\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(x))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(X_train, y_train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(X_test, y_test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['user_id', 'item_id', 'age', 'gender', 'occupation', 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
      "A batch of ages: tf.Tensor(\n",
      "[23 70 35 29 29 48 33 50 35 19 23 60 33 19 13 23 51 21 20 35 20 35 34 32\n",
      " 48 29 29 21 40 23 22 20], shape=(32,), dtype=int64)\n",
      "A batch of user_id: tf.Tensor(\n",
      "[  3 860 256 365 768 463 381 909 378  68 838 694 387 110 674 305 548 198\n",
      " 773 450  99 256 833 796 488 222 109 671 200 305 405 886], shape=(32,), dtype=int64)\n",
      "A batch of occupations: tf.Tensor(\n",
      "[b'writer' b'retired' b'none' b'lawyer' b'administrator' b'healthcare'\n",
      " b'artist' b'educator' b'student' b'student' b'student' b'programmer'\n",
      " b'entertainment' b'student' b'student' b'programmer' b'writer' b'student'\n",
      " b'student' b'educator' b'student' b'none' b'writer' b'writer'\n",
      " b'technician' b'programmer' b'other' b'programmer' b'programmer'\n",
      " b'programmer' b'healthcare' b'student'], shape=(32,), dtype=string)\n",
      "A batch of Animation: tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(32,), dtype=int64)\n",
      "A batch of targets: tf.Tensor([0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "  print('Every feature:', list(feature_batch.keys()))\n",
    "  print('A batch of ages:', feature_batch['age'])\n",
    "  print('A batch of user_id:', feature_batch['user_id'])\n",
    "  print('A batch of occupations:', feature_batch['occupation'])\n",
    "  print('A batch of Animation:', feature_batch['Animation'])\n",
    "  print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense inputs\n",
    "inputs = {\n",
    "    'age': tf.keras.layers.Input(name='age', shape=(), dtype='int8'),\n",
    "    'user_id': tf.keras.layers.Input(name='user_id', shape=(), dtype='int8'),\n",
    "    'item_id': tf.keras.layers.Input(name='item_id', shape=(), dtype='int8')\n",
    "    \n",
    "}\n",
    "inputs.update({\n",
    "    colname : tf.keras.layers.Input(name=colname, shape=(), dtype='int8') \n",
    "          for colname in ['unknown','Action', 'Adventure', 'Animation', 'Children', \n",
    "                                    'Comedy', 'Crime','Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "                                    'Horror', 'Musical','Mystery', 'Romance', 'Sci-Fi', 'Thriller', \n",
    "                                    'War', 'Western']\n",
    "})\n",
    "\n",
    "# Sparse inputs\n",
    "inputs.update({\n",
    "    colname : tf.keras.layers.Input(name=colname, shape=(), dtype='string') \n",
    "          for colname in [ 'occupation', 'gender'] \n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense features\n",
    "features = {\n",
    "    'age' : tf.feature_column.numeric_column('age'),\n",
    "    'gender': feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list\n",
    "                ('gender', vocabulary_list=['M', 'F']))\n",
    "}\n",
    "features.update(\n",
    "            {\n",
    "                categorical_feature: tf.feature_column.indicator_column(\n",
    "                    tf.feature_column.categorical_column_with_identity(categorical_feature,num_buckets=2))\n",
    "                    for categorical_feature in ['unknown','Action', 'Adventure', 'Animation', 'Children', \n",
    "                                    'Comedy', 'Crime','Documentary', 'Drama', 'Fantasy', 'Film-Noir', \n",
    "                                    'Horror', 'Musical','Mystery', 'Romance', 'Sci-Fi', 'Thriller', \n",
    "                                    'War', 'Western']\n",
    "            }\n",
    ")\n",
    "# Sparse features\n",
    "features.update({\n",
    "\n",
    "            'embedding_occupation': tf.feature_column.embedding_column(\n",
    "                tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "                'occupation', vocabulary_list=[\n",
    "                    'technician', 'executive', 'administrator', 'programmer',\n",
    "                    'marketing', 'student', 'artist', 'engineer', 'librarian',\n",
    "                    'educator', 'other', 'scientist', 'homemaker', 'salesman',\n",
    "                    'healthcare', 'entertainment', 'retired', 'writer', 'none',\n",
    "                    'lawyer', 'doctor']), 10),\n",
    "            'embedding_user_id':tf.feature_column.embedding_column(\n",
    "                feature_column.categorical_column_with_identity(\n",
    "                'user_id', num_buckets=num_users), 10),\n",
    "            'embedding_item_id':tf.feature_column.embedding_column(\n",
    "                feature_column.categorical_column_with_identity(\n",
    "                'item_id', num_buckets=num_items), 10)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_layer(x0, xl):\n",
    "    \"\"\"\n",
    "    实现一层cross layer\n",
    "    @param x0: 特征embeddings\n",
    "    @param xl: 前一层的输出结果\n",
    "    \"\"\"\n",
    "    # 1.获取xl层的embedding size\n",
    "    embed_dim = xl.shape[-1]\n",
    "    # 2.初始化当前层的W和b\n",
    "    w = tf.Variable(tf.random.truncated_normal(shape=(embed_dim,), stddev=0.01))\n",
    "    b = tf.Variable(tf.zeros(shape=(embed_dim,)))\n",
    "    # 3.计算feature crossing\n",
    "    # 下面的reshape操作相当于将列向量转换为行向量\n",
    "    x1_T = tf.reshape(xl, [-1, 1, embed_dim])\n",
    "    # 行向量与列向量的乘积结果是一个标量\n",
    "    x_lw = tf.tensordot(x1_T, w, axes=1)\n",
    "    cross = x0 * x_lw \n",
    "    return cross + b + xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_HIDDEN_UNITS = '64,32'\n",
    "NUM_CROSS_LAYERS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Deep&Cross model.\n",
    "def deep_and_cross_classifier(inputs, features, dnn_hidden_units, num_cross_layers):\n",
    "    features = tf.keras.layers.DenseFeatures(features, name='inputs')(inputs)\n",
    "    \n",
    "    # Deep\n",
    "    layers = [int(x) for x in dnn_hidden_units.split(',')]\n",
    "    for layerno, numnodes in enumerate(layers):\n",
    "        deep = tf.keras.layers.Dense(numnodes, activation='relu', name='dnn_{}'.format(layerno+1))(features)        \n",
    "\n",
    "    # Cross\n",
    "    # 初始化xl为x0\n",
    "    cross = features\n",
    "    for i in range(num_cross_layers):\n",
    "        cross = cross_layer(features, cross)\n",
    "    \n",
    "    # Concatenate Deep and Cross\n",
    "    both = tf.keras.layers.concatenate([deep, cross], name='both')\n",
    "\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid', name='pred')(both)\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = deep_and_cross_classifier(\n",
    "    inputs,\n",
    "    features = features.values(),\n",
    "    dnn_hidden_units = DNN_HIDDEN_UNITS,\n",
    "    num_cross_layers = NUM_CROSS_LAYERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, 'deep_and_cross.png', show_shapes=False, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "500/500 [==============================] - 5s 10ms/step - loss: 0.5130 - accuracy: 0.7958 - val_loss: 0.5480 - val_accuracy: 0.7659\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.5224 - accuracy: 0.7845 - val_loss: 0.5512 - val_accuracy: 0.7654\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.5156 - accuracy: 0.7903 - val_loss: 0.5500 - val_accuracy: 0.7659\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 4s 8ms/step - loss: 0.5116 - accuracy: 0.7913 - val_loss: 0.5498 - val_accuracy: 0.7659\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 4s 9ms/step - loss: 0.5117 - accuracy: 0.7909 - val_loss: 0.5569 - val_accuracy: 0.7659\n",
      "Epoch 6/10\n",
      "330/500 [==================>...........] - ETA: 1s - loss: 0.5143 - accuracy: 0.7869WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5000 batches). You may need to use the repeat() function when building your dataset.\n",
      "331/500 [==================>...........] - 3s 10ms/step - loss: 0.5144 - accuracy: 0.7868 - val_loss: 0.5505 - val_accuracy: 0.7659\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=10, \n",
    "                    steps_per_epoch=500,\n",
    "                    callbacks = [tensorboard_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.2.2 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
